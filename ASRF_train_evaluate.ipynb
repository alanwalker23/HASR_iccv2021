{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torch) (0.9.0)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alan wong\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !pip install torch\n",
    "# !pip install torchaudio\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "\n",
    "sys.path.append('./backbones/asrf')\n",
    "from libs import models\n",
    "from libs.optimizer import get_optimizer\n",
    "from libs.loss_fn import ActionSegmentationLoss, BoundaryRegressionLoss\n",
    "from libs.class_weight import get_class_weight, get_pos_weight\n",
    "from libs.dataset import ActionSegmentationDataset, collate_fn\n",
    "from libs.transformer import TempDownSamp, ToTensor\n",
    "from libs.helper import train, validate, evaluate\n",
    "from libs.checkpoint import resume, save_checkpoint\n",
    "\n",
    "from src.utils import eval_txts, load_meta\n",
    "from src.predict import predict_backbone\n",
    "import configs.asrf_config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'breakfast'     # choose from gtea, 50salads, breakfast\n",
    "split = 4            # gtea : 1~4, 50salads : 1~5, breakfast : 1~4\n",
    "model_name = 'asrf'  # always \"asrf\" in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created :./model\\asrf\\breakfast\\split_4\n",
      "Created :./result\\asrf\\breakfast\\split_4\n",
      "Created :./record\\asrf\\breakfast\n"
     ]
    }
   ],
   "source": [
    "actions_dict, \\\n",
    "num_actions, \\\n",
    "gt_path, \\\n",
    "features_path, \\\n",
    "vid_list_file, \\\n",
    "vid_list_file_tst, \\\n",
    "sample_rate,\\\n",
    "model_dir,\\\n",
    "result_dir, \\\n",
    "record_dir = load_meta(cfg.dataset_root, cfg.model_root, cfg.result_root, cfg.record_root, dataset, split, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ActionSegmentationDataset(\n",
    "        dataset,\n",
    "        transform=Compose([ToTensor(), TempDownSamp(sample_rate)]),\n",
    "        mode=\"trainval\" if not cfg.param_search else \"training\",\n",
    "        split=split,\n",
    "        dataset_dir=cfg.dataset_root,\n",
    "        csv_dir=cfg.csv_dir,\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True if cfg.batch_size > 1 else False,\n",
    "        collate_fn=collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-504e9bc7f00d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mn_stages_brb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_stages_brb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m                     \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                     )\n\u001b[1;32m-> 1160\u001b[1;33m                 return t.to(\n\u001b[0m\u001b[0;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = models.ActionSegmentRefinementFramework(\n",
    "    in_channel = cfg.in_channel,\n",
    "    n_features = cfg.n_features,\n",
    "    n_classes = num_actions,\n",
    "    n_stages = cfg.n_stages,\n",
    "    n_layers = cfg.n_layers,\n",
    "    n_stages_asb = cfg.n_stages_asb,\n",
    "    n_stages_brb = cfg.n_stages_brb\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(\n",
    "        'Adam',\n",
    "        model,\n",
    "        cfg.learning_rate,\n",
    "        momentum=cfg.momentum,\n",
    "        dampening=cfg.dampening,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "        nesterov=cfg.nesterov,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.class_weight:\n",
    "    class_weight = get_class_weight(\n",
    "        dataset=dataset,\n",
    "        split=split,\n",
    "        dataset_dir=cfg.dataset_root,\n",
    "        csv_dir=cfg.csv_dir,\n",
    "        mode=\"training\" if cfg.param_search else \"trainval\",\n",
    "    )\n",
    "    class_weight = class_weight.to(device)\n",
    "else:\n",
    "    class_weight = None\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_cls = ActionSegmentationLoss(\n",
    "        ce=cfg.ce,\n",
    "        focal=cfg.focal,\n",
    "        tmse=cfg.tmse,\n",
    "        gstmse=cfg.gstmse,\n",
    "        weight=class_weight,\n",
    "        ignore_index=255,\n",
    "        ce_weight=cfg.ce_weight,\n",
    "        focal_weight=cfg.focal_weight,\n",
    "        tmse_weight=cfg.tmse_weight,\n",
    "        gstmse_weight=cfg.gstmse,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = get_pos_weight(\n",
    "        dataset=dataset,\n",
    "        split=split,\n",
    "        csv_dir=cfg.csv_dir,\n",
    "        mode=\"training\" if cfg.param_search else \"trainval\",\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bound = BoundaryRegressionLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, cfg.max_epoch):\n",
    "    # training\n",
    "    train_loss = train(\n",
    "        train_loader,\n",
    "        model,\n",
    "        criterion_cls,\n",
    "        criterion_bound,\n",
    "        cfg.lambda_b,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        device,\n",
    "    )\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, \"epoch-\"+str(epoch+1)+\".model\"))\n",
    "    print(\"epoch: {}\\tlr: {:.4f}\\ttrain loss: {:.4f}\".format(epoch+1, optimizer.param_groups[0][\"lr\"], train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = -1\n",
    "max_val = 0.0\n",
    "max_results = dict()\n",
    "\n",
    "f = open(os.path.join(record_dir, 'split_{}_all.csv'.format(split)), 'w')\n",
    "\n",
    "writer = csv.writer(f, delimiter='\\t')\n",
    "writer.writerow(['epoch', 'accu', 'edit', \n",
    "                 'F1@{}'.format(cfg.iou_thresholds[0]),\n",
    "                 'F1@{}'.format(cfg.iou_thresholds[1]), \n",
    "                 'F1@{}'.format(cfg.iou_thresholds[2])])\n",
    "\n",
    "for epoch in range(1, cfg.max_epoch+1):\n",
    "    print('======================EPOCH {}====================='.format(epoch))\n",
    "    predict_backbone(model_name, model, model_dir, result_dir, features_path, vid_list_file_tst, \n",
    "                     epoch, actions_dict, device, sample_rate)    \n",
    "    results = eval_txts(cfg.dataset_root, result_dir, dataset, split, model_name)\n",
    "    \n",
    "    writer.writerow([epoch, '%.4f'%(results['accu']), '%.4f'%(results['edit']),\n",
    "                    '%.4f'%(results['F1@%0.2f'%(cfg.iou_thresholds[0])]),\n",
    "                    '%.4f'%(results['F1@%0.2f'%(cfg.iou_thresholds[1])]),\n",
    "                    '%.4f'%(results['F1@%0.2f'%(cfg.iou_thresholds[2])])])\n",
    "\n",
    "    curr_val = sum([results[k] for k in results.keys()])\n",
    "    max_val = max(max_val, curr_val)\n",
    "\n",
    "    if curr_val == max_val:\n",
    "        max_epoch = epoch\n",
    "        max_results = results\n",
    "\n",
    "print('EARNED MAXIMUM PERFORMANCE IN EPOCH {}'.format(max_epoch))\n",
    "print(max_results)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(record_dir, 'split_{}_best.csv'.format(split)), 'w')\n",
    "writer = csv.writer(f, delimiter='\\t')\n",
    "writer.writerow(['epoch', 'accu', 'edit', \n",
    "                 'F1@{}'.format(cfg.iou_thresholds[0]),\n",
    "                 'F1@{}'.format(cfg.iou_thresholds[1]), \n",
    "                 'F1@{}'.format(cfg.iou_thresholds[2])])\n",
    "writer.writerow([max_epoch, '%.4f'%(max_results['accu']), '%.4f'%(max_results['edit']),\n",
    "                '%.4f'%(max_results['F1@%0.2f'%(cfg.iou_thresholds[0])]),\n",
    "                '%.4f'%(max_results['F1@%0.2f'%(cfg.iou_thresholds[1])]),\n",
    "                '%.4f'%(max_results['F1@%0.2f'%(cfg.iou_thresholds[2])])])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
